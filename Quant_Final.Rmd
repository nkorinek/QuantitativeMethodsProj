---
title: "Quantative Methods Final Project"
subtitle: "Forest Fire Time Series Data"
author: Nathan Korinek, Claire Simpson
output: 
  html_document:
    css: "lab.css"
---

```{r setup, include=FALSE}
# Setup the environment
library(knitr)
knitr::opts_chunk$set(fig.align='center',fig.width=10, fig.height=6, fig.path='Figs/',  warning=FALSE, echo=TRUE, eval=TRUE, message=FALSE)

r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)
```

```{r, echo=T, eval=T, results='hide'}
library(maptools)
library(maps)
library(raster)
library(spatstat)
library(spdep)
library(ggmap)
library(ggsn)
library(randomForest) 
library(tidyr)
library(sf)
# library(caret)
library(doParallel)
# install.pacakges("rlang")#needed to fix a caret dependency/version issue
library(caret)

# Load shape file
fire_data<-st_read("Quant_Fire_Data/Quant_Fire_Data.shp")

# Set the right projection information
fire_data<-st_set_crs(fire_data, 4326)

# Reproject the fire data to EPSG:26913, which represents UTM projection
projLocs<-st_transform(fire_data, CRS("+init=epsg:26913"))

# Load shape file
simple_fire_data<-st_read("Simplified_Quant_Fire_Data/Simplified_Quant_Fire_Data.shp")

# Set the right projection information
simple_fire_data<-st_set_crs(simple_fire_data, 4326)

# Reproject the fire data to EPSG:26913, which represents UTM projection
simple_projLocs<-st_transform(simple_fire_data, CRS("+init=epsg:26913"))
```


Add Columns for Training vs. Test vs Validation data
```{r, echo=T, eval=T, results='hide'}
Test_Ids = c("CO3741010757920121016","NM3700010423620110526","CO3894510543620120617","NM3692010445620110612","CO3747210346920110607","NM3696310515520100523")
Val_Ids = c('CO3726810830320120622', 'CO3935510767920100507', 'CO4005110538520100906', 'CO3943610521720120326')

fire_data['isTest'] <-'Train'
fire_data$isTest[fire_data$Event_ID %in% Test_Ids]<-'Test'
fire_data$isTest[fire_data$Event_ID %in% Val_Ids]<-'Validation'


```


Get attributes before and after fire to Split data into pre fire and post fire data
```{r, echo=T, eval=T, results='hide'}

# Convert fire_date to a Date object
fire_data$fire_date <- as.Date(paste(fire_data$Year, fire_data$Month, fire_data$Day, sep = "-"))

# Find the columns that occurred after the fire date
# after_fire_date_cols <- names(fire_data)[sapply(names(fire_data), function(col_name) {
#   col_date <- as.Date(paste0("01-", substring(col_name, 2)), format = "%d%b%Y")
#   col_date > fire_data$fire_date
# })]
my_df <- fire_data %>% st_drop_geometry()

# selected_names <- names(my_df)[8:799] #all names with var-month-year
# Vector of month names
month_names <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")

#get new column names
attr_list <- list()
precip_list <- list()
temp_list <- list()
precip_list_post <- list()
temp_list_post <- list()
ndvi_list_post <- list()

# Loop through the desired number of attributes
for (i in 1:24) {
  #NOTE: 1 mo before fire = month in which fire occurred
  # Create the attribute name using paste0
  # Add the attribute name to the list
  attr_list[i] <- paste0("N", i, "before")
  precip_list[i] <- paste0("P", i, "before")
  temp_list[i] <- paste0("T", i, "before")
  
  #columns for after fire 
  precip_list_post[i] <- paste0("P", i, "after")
  temp_list_post[i] <- paste0("T", i, "after")
  ndvi_list_post[i] <- paste0("N", i, "after")
  
}

# Print the attribute names list
print(attr_list)

attr_list =unlist(attr_list)
precip_list = unlist(precip_list)
temp_list = unlist(temp_list)
precip_list_post = unlist(precip_list_post)
temp_list_post = unlist(temp_list_post)
ndvi_list_post = unlist(ndvi_list_post)


#iterate through rows and then cols to parse NDVI, preicp, temp for N months before/after fire
for (r in 1:nrow(my_df)){

  #get fire date
  this_fire_date = my_df$fire_date[r]
  fire_month <- as.numeric(format(this_fire_date, "%m"))
  fire_mo_name <- month_names[fire_month]
  fire_year <- format(this_fire_date, "%Y")
  
  #get index of column that represents month of fire 
  match_idx <- grep(paste('N',fire_mo_name, fire_year,sep=''), colnames(my_df))
  
  #get NDVI 24 months before the fire 
  col_indices <- seq(match_idx, match_idx - 24*3, by = -3)[1:24]
  for (i in seq_along(col_indices)){
    attr_name = attr_list[i]
    col_idx = col_indices[i]
    # print(c(colnames(my_df)[col_idx],attr_name))
    my_df[r, attr_name] <- my_df[r,col_idx]
  }
  
  #get NDVI 24 months AFTER the fire
  col_indices <- seq(match_idx+3, match_idx + 24*3, by = 3)#[1:24]
  for (i in seq_along(col_indices)){
    attr_name = ndvi_list_post[i]
    col_idx = col_indices[i]
    my_df[r, attr_name] <- my_df[r,col_idx]
  }
  
  match_idx = match_idx-1
  col_indices <- seq(match_idx, match_idx - 24*3, by = -3)[1:24]
  #get temp 24 months before fire
  for (i in seq_along(col_indices)){
    attr_name = temp_list[i]
    col_idx = col_indices[i]
    my_df[r, attr_name] <- my_df[r,col_idx]
  }
  #get temp 24 months AFTER the fire
  col_indices <- seq(match_idx+3, match_idx + 24*3, by = 3)
  for (i in seq_along(col_indices)){
    attr_name = temp_list_post[i]
    col_idx = col_indices[i]
    my_df[r, attr_name] <- my_df[r,col_idx]
  }
  
  #get precip 24 months before the fire
  match_idx = match_idx-1
  col_indices <- seq(match_idx, match_idx - 24*3, by = -3)[1:24]
  for (i in seq_along(col_indices)){
    attr_name = precip_list[i]
    col_idx = col_indices[i]
    my_df[r, attr_name] <- my_df[r,col_idx]
  }
  
  #get precip 24 months AFTER the fire 
  col_indices <- seq(match_idx+3, match_idx + 24*3, by = 3)
  for (i in seq_along(col_indices)){
    attr_name = precip_list_post[i]
    col_idx = col_indices[i]
    my_df[r, attr_name] <- my_df[r,col_idx]
  }
  
}
```


Apply Seasonal Differencing to De-trend data/ control periodicity!
```{r, echo=T, eval=T, results='hide'}

# calculate the seasonal mean per point

# Identify columns with "N" values for each month using regular expressions
n_cols <- grep("^N[A-Za-z]{3}\\d{4}$", names(my_df))

# Create a new data frame with the monthly means for each row
#old:as.data.frame(rowMeans(x[grepl("^NJan\\d{4}$", names(x))],na.rm=TRUE)),
monthly_means <- data.frame(t(apply(my_df[n_cols], 1, function(x) {
  # x <- as.numeric(x)
  cbind(mean(x[grepl("^NJan\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NFeb\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NMar\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NApr\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NMay\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NJun\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NJul\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NAug\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NSep\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NOct\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NNov\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^NDec\\d{4}$", names(x))],na.rm=TRUE)
  )
})))

# Rename columns with the month names
colnames(monthly_means) <- paste0("N", month.abb, "Mean")
Ncols <- colnames(monthly_means)

# Add any non-"N" columns to the new data frame
other_cols <- setdiff(names(monthly_means),names(my_df))
# monthly_means[other_cols] <- my_df[other_cols]

my_df[other_cols] <- monthly_means 

## same for precip
n_cols <- grep("^P[A-Za-z]{3}\\d{4}$", names(my_df))

# Create a new data frame with the monthly means for each row
#old:as.data.frame(rowMeans(x[grepl("^NJan\\d{4}$", names(x))],na.rm=TRUE)),
monthly_means <- data.frame(t(apply(my_df[n_cols], 1, function(x) {
  # x <- as.numeric(x)
  cbind(mean(x[grepl("^PJan\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PFeb\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PMar\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PApr\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PMay\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PJun\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PJul\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PAug\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PSep\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^POct\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PNov\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^PDec\\d{4}$", names(x))],na.rm=TRUE)
  )
})))

# Rename columns with the month names
colnames(monthly_means) <- paste0("P", month.abb, "Mean")
Pcols <- colnames(monthly_means)

# Add any non-"N" columns to the new data frame
other_cols <- setdiff(names(monthly_means),names(my_df))
# monthly_means[other_cols] <- my_df[other_cols]

my_df[other_cols] <- monthly_means 

## same for TEMPERATURE
n_cols <- grep("^T[A-Za-z]{3}\\d{4}$", names(my_df))

# Create a new data frame with the monthly means for each row
monthly_means <- data.frame(t(apply(my_df[n_cols], 1, function(x) {
  # x <- as.numeric(x)
  cbind(mean(x[grepl("^TJan\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TFeb\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TMar\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TApr\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TMay\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TJun\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TJul\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TAug\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TSep\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TOct\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TNov\\d{4}$", names(x))],na.rm=TRUE),
    mean(x[grepl("^TDec\\d{4}$", names(x))],na.rm=TRUE)
  )
})))

# Rename columns with the month names
colnames(monthly_means) <- paste0("T", month.abb, "Mean")
Tcols <- colnames(monthly_means)


# Add any non-"N" columns to the new data frame
other_cols <- setdiff(names(monthly_means),names(my_df))
# monthly_means[other_cols] <- my_df[other_cols]

my_df[other_cols] <- monthly_means 


# final_df <- my_df

### "^T[A-Za-z]{3}\\d{4}$"
all_month_cols <- c(Ncols,Pcols,Tcols)
for (month_col in all_month_cols) { #iterate through all variable mean monthly columns (36)
  my_exp <- paste0("^",substr(month_col, 1, 1), substr(month_col, 2, 4), "\\d{4}$")
  my_df[, grepl(my_exp, names(my_df))] <- 
    my_df[, grepl(my_exp, names(my_df))] - my_df[, month_col]
}

```

  
Normalize Data
```{r, echo=T, eval=T, results='hide'}

# Select columns to normalize
my_df['id'] <- seq(1:nrow(my_df))
dont_scale <- c("id","Event_ID", "Month","Day","Year","fire_date","isTest")
cols_to_normalize <- dplyr::setdiff(names(my_df), dont_scale)

# Normalize selected columns
df_scaled <- my_df %>% 
  dplyr::select(cols_to_normalize) %>% 
  dplyr::mutate_if(is.numeric, scale) %>%
  cbind(my_df[dont_scale])#, my_df[dont_scale])

my_df <-df_scaled
```


Here: ACTUALLY split data into training and test :)
```{r, echo=T, eval=T, results='hide'}

#split into train/test sets (val is part of train right now)
train_Xy <- my_df %>% dplyr::filter(my_df$isTest != 'Test') #currently this keeps validation rows in training set
# train_y <- my_df %>% dplyr::filter(my_df$isTest != 'Test')
test_Xy <- my_df %>% dplyr::filter(my_df$isTest == 'Test')
# test_y <- my_df %>% dplyr::filter(my_df$isTest == 'Test')


# Create input and output data frames
static_list <- c('slope','chili','elevation','aspect','mtpi')#colnames(my_df)[1:6]
predictor_cols <- c(attr_list,precip_list, temp_list, static_list) #X (predictor) column names
target_cols <- c(ndvi_list_post, temp_list_post, ndvi_list_post) #y (target) col names
# all_cols <- c(target_cols,predictor_cols)
# train_Xy <- train_Xy[all_cols]
# test_Xy <- test_Xy[c(predictor_cols,target_cols)]
# train_y <- test_y[target_cols]
# test_y <- test_y[target_cols]


```

Random Forests Analysis

We will fire run recursive feature elimination to get a sense of which predictor
variables are the most important. We have already prepared the data for input, 
including transforming the data to remove the seasonal fluctuations (making it
stationary),

Here: remove NAs

```{r, echo=T, eval=T, results='hide'}
#random forests


# if installing caret doesnt work try:
# library(devtools)
# devtools::install_url("https://cran.r-project.org/src/contrib/caret_6.0-78.tar.gz")

#subset out columns from dataset (remove non-predictors/targets)
# names <- names(fire_data)
# to_remove <- c("Event_ID", "geometry", "index_righ")
# keep_names <- names[! names %in% to_remove]
# keep_names
# fire_data_4_model <- fire_data[keep_names]
# fire_data_4_model <- fire_data_4_model %>% st_drop_geometry()

#check for complete cases (will remove everything bc some columns are blank...)
# fire_data_4_model <- fire_data_4_model[complete.cases(fire_data_4_model), ]

#drop row where column 'elevation' is NA
train_Xy<- train_Xy %>% tidyr::drop_na(elevation)
test_Xy<- test_Xy %>% tidyr::drop_na(elevation)

#drop any column where there is an NA value
# train_X<-train_X[ , apply(train_X, 2, function(x) !any(is.na(x)))]

#TEMPORARY until we do interpolation to fill missing values
train_Xy[is.na(train_Xy)] <- 0
test_Xy[is.na(test_Xy)] <- 0


#Run Recursive Feature Elimination

#RFE parameters
# subsets <- seq(20, 700, by=20)#c(1:(length(fire_data_4_model)-1))
# # seeds <- vector(mode = "list", length = 51)
# seeds <- vector(mode = "list", length = 35)
# for(i in 1:75) seeds[[i]] <- sample.int(1000, length(subsets) + 1)
# seeds[[76]] <- sample.int(1000, 1)
# 
# ctrl.RFE <- caret::rfeControl(functions = rfFuncs,
#                        method = "repeatedcv",
#                        number = 15,
#                        repeats = 5,
#                        seeds = seeds, 
#                        verbose = FALSE)
# 
# #this code makes it run in parallel
# c1 <- makeCluster(detectCores()-1)
# registerDoParallel(c1)
# set.seed(9)
# target <- c('NApr2021')
# rf.RFE <- rfe(x = fire_data_4_model[! fire_data_4_model %in% target],
#               y = fire_data_4_model$NApr2021,
#               sizes = subsets,
#               # na.rm=TRUE,
#               rfeControl = ctrl.RFE,
#               allowParallel = TRUE
# )
# stopCluster(c1)              
# 
# gc()
# 
# # Look at the results
# rf.RFE
# 
# rf.RFE$fit
# 
# rf.RFE$results
# 
# plot(rf.RFE) # default plot is for Accuracy, but it can also be changed to Kappa
# plot(rf.RFE, metric="Kappa", main='RFE Kappa')
# plot(rf.RFE, metric="Accuracy", main='RFE Accuracy')

```

We now can run the Random Forests model.

Options for RF strategies:
1.) create n RF models, one for each timestep we want to predict. Say, 12 different RF models, 
1 for each of the 12 months in the second year after the fire. We fire need to create 
12 training and test sets, where the training data consists of the 12 months immediately 
preeceeding the fire

2.) Create 1 RF model where there is an input predictor variable (feature) that 
tells the model which timestep after the fire the model is supposed to predict

```{r, echo=T, eval=T, results='hide'}
#Run Option 1:
#define R2 
r_squared <- function(pred, target) {
  ss_residual <- sum((target - pred) ^ 2)
  ss_total <- sum((target - mean(target)) ^ 2)
  return(1 - ss_residual / ss_total)
}


#store RMSE of test set in this dataframe:
rmse_df <- data.frame()
r2_df <- data.frame()
for (i in 1:24){
  print(i)
  #create training set with t timesteps pre-prediction
  #e.g. first want to predict NDVI for month after fire, using 24-months pre-fire 
  
  #get list of attributes to keep as predictors:
  end <- length(attr_list)
  #want include attributes from 1 mo before through 
  range_i <- seq_len(25 - i)
  keep_attr_pre <- c(attr_list[range_i], precip_list[range_i], temp_list[range_i])
  len <- length(attr_list) - length(attr_list[i:end]) 
  #^ how many timesteps do we need in order to ensure that we have 24 pre-prediction inputs?
  if (len>0){
    keep_attr_post <- c(ndvi_list_post[1:len], precip_list_post[1:len], temp_list_post[1:len])
  }else{
    keep_attr_post <- c()#ndvi_list_post[1:1])#, precip_list_post[1:1], temp_list_post[1:1])
  }
  
  #get attribute to keep as target
  target_col <- ndvi_list_post[i]
  print(c("target:", target_col))
  #concat attribute lists to keep as predictors/targets
  keep <- c(keep_attr_pre, keep_attr_post, static_list,target_col)
  
  #split data into train and test
  current <- train_Xy[keep]
  current_test <- test_Xy[keep]

  #run RF!!
  
  #subsets max number should be the same or equal to the number of covariates being used
  # determine number of covariates
  subsets <- length(keep)

  # set seeds to get reproducable results when running the process in parallel
  set.seed(12)
  seeds <- vector(mode = "list", length=76)
  for(j in 1:75) seeds[[j]] <- sample.int(1000, length(1:subsets) + 1)
  seeds[[76]] <- sample.int(1000, 1)
  
  
  # Create the formula for randomForest
formula <- as.formula(paste(target_col, paste(names(current)[!names(current) %in% target_col], collapse = "+"), sep = "~"))
  
  set.seed(12)
  # Fit the random forest model
  rf_model <- randomForest(formula=formula, data = current, importance = TRUE, ntree=500,mtry=50,type='regression')
  
  #get training r2 to ensure model training correctly..
  train_pred <- rf_model$predicted
  print(c("training R2",r_squared(train_pred, current$N1after)))
  
  
  # Make predictions on the test set
  rf_pred <- predict(rf_model, newdata = current_test)
  
  # Check the accuracy of the model

  
  #r2 on test set
  actual <- current_test[[target_col]]
  test_r2 <- r_squared(rf_pred, actual)
  print(c("test R2:",test_r2))
  r2_df[1, target_col] <- test_r2
  
  
  # varImpPlot(rf_model)
  
  test_rmse <- sqrt(mean((actual - rf_pred)^2))
  print(c("RMSE on test set:", test_rmse))
  rmse_df[1, target_col] <- test_rmse
  
  # plot(current_test$T1after,rf_pred, xlim=c(40,160), ylim=c(40,160),asp=1)
  
  #store predictions in dataframe to plot 
  test_Xy[paste("pred_",target_col,sep='')] = rf_pred 

  
}
```

Visualize the results
```{r, echo=T, eval=T, results='hide'}

print(t(r2_df))
print(rmse_df)

#plot relationship between post-fire timesteps and accuracy metrics
plot(t(r2_df), main= "R^2 by Timestep", xlab="Months After Fire", ylab="R^2") #transposed
plot(t(rmse_df), main="RMSE by Timestep", xlab="Months After Fire", ylab="RMSE")

#want to plot an example sample 
# Create some sample data
rand_num=10

x <- 1:24
truth_cols <- grep("^N\\d{1,2}after$", names(test_Xy),value=TRUE)
truth <- t(test_Xy[rand_num,truth_cols])
pred_cols <- grep("^pred_N\\d{1,2}after$", names(test_Xy),value=TRUE)
pred_cols
pred <- t(test_Xy[rand_num,pred_cols])


plot(x, truth,
     type="b",
     col='blue',
     main=paste0("Predicted and True NDVI for Test Sample ", as.character(rand_num)),
     xlab = "Months After Fire",
     ylab = "NDVI")

# Add the second list to the plot
points(x, pred, type='b',col = "red")
legend("topright", legend = c("True", "Predicted"), col = c("blue", "red"), lty = 1)



```


Clustering Analysis:
Run Kmeans to group the points and determine which points are most similar to one another 
This will help reveal which fires are most similar 
```{r, echo=T, eval=T, results='hide'}
#kmeans

set.seed(12)

# output_df <- my_df[, !(names(my_df) %in% c("fire_date", after_fire_date_cols))]

#use simple_fire_data
#remove NAs - TEMPORARY?
non_na_cluster<- simple_fire_data %>% tidyr::drop_na(elevation)
non_na_cluster[is.na(non_na_cluster)] <- 0

cluster_data <- non_na_cluster[, !names(non_na_cluster) %in% c("Event_ID", "geometry", "Year","Month","Day","severity")]
cluster_data <-  cluster_data %>% st_drop_geometry()
names(cluster_data)


## Elbow Plot
library(factoextra)

# Create elbow plot
elbow_plot <- fviz_nbclust(cluster_data, kmeans, method = "wss")
print(elbow_plot)



# Run kmeans with 3 clusters
k <- kmeans(cluster_data, centers = 6)

# View the cluster assignments
# k$cluster

#add clusters back to original dataframe
non_na_cluster['kmeans'] <- k$cluster

#plot clusters on map
#add lat and long
non_na_cluster$Longitude <- st_coordinates(non_na_cluster$geometry)[, 1]
non_na_cluster$Latitude <- st_coordinates(non_na_cluster$geometry)[, 2]

ggplot() +
  geom_sf(data = non_na_cluster) +
  geom_point(aes(x = Longitude, y = Latitude, color = factor(kmeans)), data=non_na_cluster, size = 2) +
  scale_color_discrete(name = "Kmeans")



```
